{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Exploration and Visualization of Algorithms for Machine Learning and Data Science\n",
    "\n",
    "Here is an overview of the topics, split into separate notebooks.\n",
    "\n",
    "While most notebooks are standalone and can be viewed in any order, it is generally advisable to follow the given order for each section.\n",
    "\n",
    "## Linear regression\n",
    "\n",
    "1. [Linear Regression](notebooks/LinearRegression.ipynb)\n",
    "\n",
    "## Sampling methods\n",
    "\n",
    "1. [Introduction. Inversion Sampling](notebooks/Sampling_Intro.ipynb)\n",
    "2. [Rejection sampling](notebooks/Sampling_Rejection.ipynb)\n",
    "3. [Importance sampling](notebooks/Sampling_Importance.ipynb)\n",
    "4. [Markov chain Monte-Carlo (MCMC) sampling: Metropolis-Hastings algorithm](notebooks/Sampling_MCMC.ipynb)\n",
    "5. [Gibbs Sampling](notebooks/Sampling_Gibbs.ipynb)\n",
    "    * [Example. Gibbs sampling for Gaussian mixture model](notebooks/Sampling_GaussianMixture_Example.ipynb)\n",
    "6. [Slice sampling](notebooks/Sampling_Slice.ipynb)\n",
    "7. [Hamiltonian Monte Carlo (HMC) sampling](notebooks/Sampling_HMC.ipynb)\n",
    "8. [PyStan](notebooks/Sampling_PyStan.ipynb)\n",
    "\n",
    "## Gradient descent methods\n",
    "1. [Introduction. Gradient and stochastic gradient descent](notebooks/GradientDescent_Intro.ipynb)\n",
    "2. [Variants. Momentum, Nesterov, Adagrad, RMSProp and Adam](notebooks/GradientDescent_Variants.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
