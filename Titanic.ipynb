{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_palette('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Trainings und Testdaten werden importiert ###\n",
    "# training_data = pd.read_csv(\"/Users/maren/Downloads/train.csv\")\n",
    "# test_data = pd.read_csv('/Users/maren/Downloads/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engeneer_function(training_data, test_data):\n",
    "    #### FEATURE ENGINEERING AND EXPLORATION ####\n",
    "    passengerId = test_data['PassengerId'] # Aufheben um später die Daten einfach zu vergleichen\n",
    "\n",
    "    # Die PassengerID trägt nicht zum Überleben oder Sterben bei, deshalb kann sie entfernt werden\n",
    "    training_data.drop(labels='PassengerId', axis=1, inplace=True) \n",
    "    test_data.drop(labels='PassengerId', axis=1, inplace=True)\n",
    "    # axis = 1: eine Spalte wird gedropped, inplace = True: die Aktion wird direkt auf das Element ausgeführt, \n",
    "    # sonst müsste man der Operation eine neue Variable zuordnen also new_test_data = test_data.drop(..)\n",
    "    \n",
    "    # Titel\n",
    "    training_data['Title'] = training_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "    test_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "\n",
    "    # Namenlänge\n",
    "    training_data['Name_Len'] = training_data['Name'].apply(lambda x: len(x))\n",
    "    test_data['Name_Len'] = test_data['Name'].apply(lambda x: len(x))\n",
    "\n",
    "    # Das eigentliche Namenslabel wird entfernt, weil hieraus kein Mehrwert mehr entsteht\n",
    "    training_data.drop(labels='Name', axis=1, inplace=True)\n",
    "    test_data.drop(labels='Name', axis=1, inplace=True)\n",
    "    \n",
    "    # Auf einen Buchstaben kommt es nicht an, daher werden die Namen durch 10 geteilt um eine Ahnung zu bekommen\n",
    "\n",
    "    test_data.Name_Len = (test_data.Name_Len/10).astype(np.int64)+1\n",
    "    training_data.Name_Len = (training_data.Name_Len/10).astype(np.int64)+1\n",
    "    \n",
    "    \n",
    "    ### AGE ###\n",
    "    ## Auch hier macht es keinen Unterschied, ob jemand 61 oder 62 Jahre alt ist. Deshalb werden die Passagiere in 5 \n",
    "    # Altersklassen eingeteilt\n",
    "\n",
    "    # Taking care of null values in Age \n",
    "    full_data = pd.concat([training_data, test_data])\n",
    "\n",
    "    # Null Ages in Training set (177 null values)\n",
    "    train_age_mean = full_data.Age.mean()\n",
    "    train_age_std = full_data.Age.std()\n",
    "    train_age_null = training_data.Age.isnull().sum()\n",
    "    rand_tr_age = np.random.randint(train_age_mean - train_age_std, train_age_mean + train_age_std, size=train_age_null)\n",
    "    training_data['Age'][np.isnan(training_data['Age'])] = rand_tr_age\n",
    "    training_data['Age'] = training_data['Age'].astype(int) + 1\n",
    "\n",
    "    # Null Ages in Test set (86 null values)\n",
    "    test_age_mean = full_data.Age.mean()\n",
    "    test_age_std = full_data.Age.std()\n",
    "    test_age_null = test_data.Age.isnull().sum()\n",
    "    rand_ts_age = np.random.randint(test_age_mean - test_age_std, test_age_mean + test_age_std, size=test_age_null)\n",
    "    test_data['Age'][np.isnan(test_data['Age'])] = rand_ts_age\n",
    "    test_data['Age'] = test_data['Age'].astype(int)\n",
    "\n",
    "    training_data.Age = (training_data.Age/15).astype(np.int64)\n",
    "    test_data.Age = (test_data.Age/15).astype(np.int64) + 1\n",
    "    \n",
    "    \n",
    "    ### FAMILY SIZE ###\n",
    "    training_data['FamilySize'] = training_data['SibSp'] + training_data['Parch'] + 1\n",
    "    test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "    \n",
    "    \n",
    "    ### TRAVEL ALONE ###\n",
    "    # Neue Spalte für isAlone: 0 = nicht alleine, 1 = reist alleine\n",
    "    training_data['isAlone'] = training_data['FamilySize'].map(lambda x: 1 if x == 1 else 0)\n",
    "    test_data['isAlone'] = test_data['FamilySize'].map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "    # Alte Spalten werden gelöscht\n",
    "    training_data.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "    test_data.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "    ### TICKET LENGTH ###\n",
    "    # Neue Spalte für die Länge des Tickets\n",
    "    training_data['Ticket_Len'] = training_data['Ticket'].apply(lambda x: len(x))\n",
    "    test_data['Ticket_Len'] = test_data['Ticket'].apply(lambda x: len(x))\n",
    "\n",
    "    # Lösche Spalten des Tickets\n",
    "    training_data.drop(labels='Ticket', axis=1, inplace=True)\n",
    "    test_data.drop(labels='Ticket', axis=1, inplace=True) \n",
    "\n",
    "    ### CABIN ###\n",
    "    \n",
    "    # hasCabin Feature, da die Kabinennummer nicht viel über die Personen aussagt\n",
    "    training_data['hasCabin'] = training_data.Cabin.notnull().astype(int)\n",
    "    test_data['hasCabin'] = test_data.Cabin.notnull().astype(int)\n",
    "\n",
    "    # drop der unnötigen Daten\n",
    "    training_data.drop(labels='Cabin', axis=1, inplace=True)\n",
    "    test_data.drop(labels='Cabin', axis=1, inplace=True)\n",
    "\n",
    "    ### FARE ###\n",
    "    test_data['Fare'][np.isnan(test_data['Fare'])] = test_data.Fare.mean()\n",
    "    training_data.Fare = (training_data.Fare /20).astype(np.int64) + 1 \n",
    "    test_data.Fare = (test_data.Fare /20).astype(np.int64) + 1 \n",
    "    \n",
    "    ### EMBARKED ###\n",
    "    training_data['Embarked'] = training_data['Embarked'].fillna('S') # S ist der häufigste Einstiegsort\n",
    "    return training_data, test_data\n",
    "\n",
    "# training_data, test_data = data_engeneer_function(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspection der Trainingsdaten ###\n",
    "# training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspection der Testdaten ###\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bestimmung der Fehlenden Werte in den Daten ###\n",
    "# training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_survival(data_frame):\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # figsize = (breite, höhe)\n",
    "    axes[0].set_title(\"Pclass vs Frequency\")\n",
    "    axes[1].set_title(\"Pclass vise Survival rate\")\n",
    "    # countplot zählt wie oft ein Feature vorkam und stellt es in einem Balkendiagramm dar (eine Art Histogram)\n",
    "    fig1_pclass = sns.countplot(data=data_frame, x='Pclass', ax=axes[0])\n",
    "    fig2_pclass = sns.barplot(data=data_frame, x='Pclass',y='Survived', ax=axes[1])\n",
    "    # data: Trainingsdaten, x,y: Feature aus den Daten, ax: die plt Axen von oben, für Titel und Größe\n",
    "    print(data_frame[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Erkenntnis: ####\n",
    "# Passagiere aus der 1. Klasse haben eine deutlich höhere Überlebenschance als Passagiere aus der 3. Klasse\n",
    "## Gründe ? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Name ###\n",
    "# Der Titel oder die länge des Namens kann Aufschluss darüber geben, wie die Überlebenschancen stehen \n",
    "# Viele Namen = Zeichen von Wohlstand \n",
    "# show_class_survival(training_data)\n",
    "# print (training_data[['Name_Len', 'Survived']].groupby(['Name_Len'], as_index=False).mean())\n",
    "def show_title_survival(data_frame):\n",
    "    \n",
    "    fx, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    axes[0].set_title(\"Title vs Frequency\")\n",
    "    axes[1].set_title(\"Title vise Survival rate\")\n",
    "    fig1_title = sns.countplot(data=data_frame, x='Title', ax=axes[0])\n",
    "    fig2_title = sns.barplot(data=data_frame, x='Title',y='Survived', ax=axes[1])\n",
    "    \n",
    "    print (data_frame[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
    "    print (data_frame[['Title', 'Survived']].groupby(['Title'], as_index=False).count())#.mean())\n",
    "# show_title_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Erkenntnis: ####\n",
    "# Passagiere mit Sir, Lady, Ms im Titel haben höhere Überlebenschancen\n",
    "# Mr hat die geringsten Überlebenschancen\n",
    "# Längere Namen -> höhere Chancen\n",
    "## Gründe ? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Geschlecht und Alter###\n",
    "# Frauen und Kinder zu erst?\n",
    "def show_gender_survival (data_frame):\n",
    "    # Geschlecht\n",
    "    print(data_frame[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean())\n",
    "\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    axes[0].set_title(\"Gender vs Frequency\")\n",
    "    axes[1].set_title(\"Gender vise Survival rate\")\n",
    "    fig1_gen = sns.countplot(data=data_frame, x='Sex', ax=axes[0])\n",
    "    fig2_gen = sns.barplot(data=data_frame, x='Sex', y='Survived', ax=axes[1])\n",
    "# show_gender_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_age_survival(data_frame):\n",
    "    # Alter\n",
    "\n",
    "    # Wie oben festgestellt, gibt es viele fehlende Werte beim Alter, deshalb werden diese entfernt\n",
    "    training_age_n = data_frame.Age.dropna(axis=0)\n",
    "\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "    axes[0].set_title(\"Age vs frequency\")\n",
    "    axes[1].set_title(\"Age vise Survival rate\")\n",
    "    fig1_age = sns.distplot(a=training_age_n, bins=15, ax=axes[0], hist_kws={'rwidth':0.7})\n",
    "\n",
    "    # Creating a new list of survived and dead\n",
    "\n",
    "    pass_survived_age = data_frame[data_frame.Survived == 1].Age\n",
    "    pass_dead_age = data_frame[data_frame.Survived == 0].Age\n",
    "\n",
    "    axes[1].hist([data_frame.Age, pass_survived_age, pass_dead_age], bins=5, range=(0, 100), label=['Total', 'Survived', 'Dead'])\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(training_data[['Age', 'Survived']].groupby(['Age'], as_index = False).mean())\n",
    "# show_age_survival(pd.read_csv(\"/Users/maren/Downloads/train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Erkenntnis: ####\n",
    "# Frauen haben eindeutig die höhere Überlebensrate\n",
    "# Die meisten Passagiere sind zwischen 20-40 Jahren alt\n",
    "# In den Altersgruppen sind die Überlebensraten für junge Leute und 40 - 60 Jährige am Besten\n",
    "## Gründe ? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Familiengröße ###\n",
    "# Wie schon beschrieben, kann dies ein Indikator für Wohlstand sein\n",
    "def show_family_size_survival(data_frame):    \n",
    "    # FamilySize = SibSp + Parch + 1\n",
    "\n",
    "\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "    axes[0].set_title('Family Size counts')\n",
    "    axes[1].set_title('Survival Rate vs Family Size')\n",
    "    fig1_family = sns.countplot(x=data_frame.FamilySize, ax=axes[0], palette='cool')\n",
    "    fig2_family = sns.barplot(x=data_frame.FamilySize, y=data_frame.Survived, ax=axes[1], palette='cool')\n",
    "    \n",
    "    print(data_frame[['FamilySize', 'Survived']].groupby(data_frame['FamilySize'], as_index=False).mean())\n",
    "# show_family_size_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Erkenntnis: ####\n",
    "# Die meisten Passagiere reisen alleine\n",
    "# Passagiere aus Familien mit 3 - 4 Mitgliedern haben die höchsten Überlebenschancen\n",
    "## Gründe ? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alleine Reisend ###\n",
    "def show_travel_alone_survival(data_frame):\n",
    "    # Plot\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig1_alone = sns.countplot(data=data_frame, x='isAlone', ax=axes[0])\n",
    "    fig2_alone = sns.barplot(data=data_frame, x='isAlone', y='Survived', ax=axes[1])\n",
    "# show_travel_alone_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ticket Länge ###\n",
    "def show_ticket_lenght_survival(data_frame):\n",
    "    # Plot\n",
    "    fx, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    axes[0].set_title(\"Ticket Length vs Frequency\")\n",
    "    axes[1].set_title(\"Length vise Survival rate\")\n",
    "    fig1_tlen = sns.countplot(data=data_frame, x='Ticket_Len', ax=axes[0])\n",
    "    fig2_tlen = sns.barplot(data=data_frame, x='Ticket_Len',y='Survived', ax=axes[1])\n",
    "# show_ticket_lenght_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## In diesem Fall ist es nicht sicher, ob die länge des Tickets die Genauigkeit des Algorithmus verbessert,\n",
    "## da die Unterschiede insignifkant sind\n",
    "## Es hat sich allerdings ergeben, dass es die Performance verbessert!\n",
    "## Nicht immer sind die wichtigen Daten so ersichtlich wie bei z.B. Geschlecht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cabin###\n",
    "def show_cabin_survival(data_frame):\n",
    "    # plot\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig1_hascabin = sns.countplot(data=data_frame, x='hasCabin', ax=axes[0])\n",
    "    fig2_hascabin = sns.barplot(data=data_frame, x='hasCabin', y='Survived', ax=axes[1])\n",
    "# show_cabin_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fare ###\n",
    "def show_fare_survival(data_frame):\n",
    "    \n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "    fig1_fare = sns.distplot(a=data_frame.Fare, bins=15, ax=axes[0], hist_kws={'rwidth':0.7})\n",
    "    fig1_fare.set_title('Fare vise Frequency')\n",
    "\n",
    "    # Creating a new list of survived and dead\n",
    "\n",
    "    pass_survived_fare = data_frame[data_frame.Survived == 1].Fare\n",
    "    pass_dead_fare = data_frame[data_frame.Survived == 0].Fare\n",
    "\n",
    "    axes[1].hist(x=[data_frame.Fare, pass_survived_fare, pass_dead_fare], bins=5, label=['Total', 'Survived', 'Dead'],\\\n",
    "            log=True)\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title('Fare vise Survival')\n",
    "    plt.show()\n",
    "    \n",
    "    print(data_frame[['Fare','Survived']].groupby(['Fare'], as_index = False).mean())\n",
    "# show_fare_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Höhere Fare Kosten, höhere Überlebenschancen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_embarked_survival(data_frame):\n",
    "    fx, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "    axes[0].set_title('Embarked Counts')\n",
    "    axes[1].set_title('Survival Rate vs Embarked')\n",
    "    fig1_embarked = sns.countplot(x=data_frame.Embarked, ax=axes[0])\n",
    "    fig2_embarked = sns.barplot(x=data_frame.Embarked, y=training_data.Survived, ax=axes[1])\n",
    "# show_embarked_survival(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Die meisten steigen in Southhampoton ein\n",
    "# Die besten Chancen hat man, wenn man in Cherbourg einstieg (hier stiegen die meisten 1. Klasse Passagiere ein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(training_data):\n",
    "    \n",
    "    X = training_data.iloc[:, 1:12].values\n",
    "    y = training_data.iloc[:, 0].values\n",
    "    \n",
    "    ### LABEL ENCODER ###\n",
    "    label_encoder_sex_tr = LabelEncoder()\n",
    "    label_encoder_title_tr = LabelEncoder()\n",
    "    label_encoder_embarked_tr = LabelEncoder()\n",
    "    X[:, 1] = label_encoder_sex_tr.fit_transform(X[:, 1])\n",
    "    X[:, 5] = label_encoder_title_tr.fit_transform(X[:, 5])\n",
    "    X[:, 4] = label_encoder_embarked_tr.fit_transform(X[:, 4])\n",
    "    \n",
    "    # Splitting the dataset into training and test set\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.17)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    # Skaliert die Daten, sodass sie einheitlich nutzbar sind (zw -1 und 1)\n",
    "    scaler_x = MinMaxScaler((-1,1))\n",
    "    X_train = scaler_x.fit_transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "# X_train, X_test, y_train, y_test = prepare_data(training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
